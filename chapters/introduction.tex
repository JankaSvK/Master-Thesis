\chapter*{Introduction}
\addcontentsline{toc}{chapter}{Introduction}

In the last decades, we witnessed a massive jump in the amount of digital information that every person owns {\color{red} maybe keeps?}. {\color{red} Looking} Back 20-30 years ago, people used to record only several hours of their lives to capture the most valuable moments. Now, {\color{red} according to available estimates} it is more than 300 hours of multimedia {\color{red} data} uploaded every minute only to YouTube {\color{red} add reference}. Decreasing prices and wide availability of the recording electronics (especially phones) are causing an increase in the number {\color{red} amount/volume?} of multimedia {\color{red} data} taken each {\color{red} every?} day. The societal inclination of the need to share the information with the world increases our need to capture every moment {\color{red} not everyone shares data...}.

This significant increase in the number of multimedia {\color{red} volume of MM data...} brings several new challenges, as the need for effective search. The researches investigated several approaches to tackle effective search {\color{red} tahle veta sem moc nesedi}. At the same time, also companies try to help their customers to organize a vast amount of multimedia {\color{red} data} (e.g., Google Photos, YouTube). At the same time {\color{red} podruhe ve dvou vetach}, we lack solutions for personal use {\color{red} to bych netvrdil}. The requirements for user-friendly solutions are an option to process their videos and easy-to-use interface {\color{red} co ma rikat tahle veta?}.

The main barrier to user end product solution is the excessive computability requirements {\color{red} nejen...}. Even though we will not be able to {\color{red} we do not} tackle this problem in this thesis, we present {\color{red} investigate?} a solution which can be a base stone {\color{red} promising?} for easy to use programs to search for videos.

We focus on the {\color{red} search} scenario where a user searches for an {\color{red} one?} exact known scene in a database. For example, the user recalls a memory, which corresponds to the search{\color{red}ed} scene. This task of searching for a known scene is known as a known-item search (KIS) {\color{red} 3x known in a row...}. We can further specify {\color{red} divide?} this {\color{red} scenario} by different {\color{red} prior} knowledge about the scene. For this thesis, we work only with visual KIS tasks, i.e., an image of the scene is available {\color{red} memorized?} (or presented).

For the past several years, researchers organize annual competitions in order to increase the interest in user-participated {\color{red} user-centered?} multimedia search. One, for example, is TRECVID (TODO: reference) {\color{red} ten je zrovna spis na automatic search}. The creation {\color{red} organization} of competitions helped to create rich, unified datasets {\color{red} spis to podporuje vyzkum obecne, datasety vznikaji i bez soutezi}.

In this thesis, we tackle the KIS task with two different approaches: 
\begin{enumerate}
  \item Visual Search with a known position of the key objects in the scene.
  \item Traversing faces in the dataset.
\end{enumerate}

In the first approach, we focus on searching the scenes via only visual similarity {\color{red} models?} together with the approximate position of key objects in the scene. Users can create a collage of images, which remind{\color{red}s} her {\color{red} them?} of the {\color{red} searched} scene and then traverse {\color{red} browse top ranked?} available scenes for the match.

The second approach is {\color{red} an} experimental verification {\color{red} test? of} possibility for visual traversing through a colossal {\color{red} larger?} dataset of faces. To present a user with a feasible amount of faces in one display, we tackle the challenge of organizing faces in a human-comprehensible {\color{red} readable?} way.

Our goal is to examine those two approaches and provide user-friendly interfaces for the user to search through the dataset. During the evaluation, we focus on We evaluate the success rate of each the mentioned approach -- i.e., how many times was the user able to find the scene. {\color{red} spis automatic evaluations pro nasbirane dotazy...}

The following chapters start with the overview of Related Work on solving KIS task. Then we continue with the summarizing {\color{red} summarization of} some key concept{\color{red}s} used in the Preliminaries {\color{red} jako ze RW?}. Afterward, the key part of the thesis is presented in two chapters. The first one focuses on solving the KIS task based on the visual similarity together with spatial information. The second chapter focuses on traversing through {\color{red} a hierarchical structure that organizes images of} faces {\color{red} with respect to their similarity}. Both chapters include evaluation sections. As the appendix, we include both Programmers and User documentation.